# **SceneTrans：面向自然场景的图像文本寻译方法**



**摘要**：**目的** 现有自然场景文本编辑方法聚焦在仅包含单一文本内容图像块的同语编辑，无法实现跨语言文本编辑。针对此问题，本文提出一种端到端的英文到中文自然场景图像文本图像寻译框架SceneTrans，实现自然场景图像文本的精准定位、英文到中文的跨语言翻译及视觉风格一致的图像文本编辑。**方法** 首先，在图像文本定位和翻译方面，以MiniCPM-V 2.6多模态大模型为基线，设计基于位置增强提示模板的指令微调策略实现文本定位与翻译的联合学习，并采用视觉侧LoRA轻量化微调方案保留模型原生翻译能力；其次，在图像文本编辑方面，以扩散生成模型为基础构建中文文本编辑模块，设计中文字形结构编码器实现中文字形先验的精准建模，同时引入中文字形识别监督机制保障生成图像文本的字形准确性；最后，为解决领域内跨语言场景文本寻译数据匮乏的难题，构建英中配对的SynthTrans专用数据集，该数据集基于真实街道场景背景与多样化中英兼容字体，合成了20万对包含弯曲、倾斜等复杂字形变换的英中匹配自然场景文本图像，为模型的有效训练与全面验证提供了高质量数据支撑。**结果** 实验在Total-Text、MSRA-TD500、ICDAR2015等文本检测数据集及自建SynthTrans编辑数据集上与其他方法进行了比较。在图像文本定位任务中，所提方法的F1值接近主流模型的检测效果；在图像文本编辑任务上，相比于TextCtrl、DiffSTE等方法，所提方法的SSIM值达0.622、PSNR值达18.51，文本渲染准确率(ACC)提升至71.13%，归一化编辑距离(NED)达0.7837；对比实验与消融实验结果证明所提的字形结构编码与识别监督机制可有效保障中文文本生成的结构准确性与风格一致性，整体框架具备高效的跨语言场景图像文本寻译能力。**结论** 本文所提出的端到端寻译框架，实现了自然场景图像文本“定位-翻译-编辑”的一体化流程，可生成字形精确、与原始图像文本风格一致的中文图像文本，突破了传统方法的无法定位及同语编辑的局限，为自然场景图像文本寻译提供了新的技术方案与数据集支撑。



------

SynthTrans数据集示例：
![image-20251209154221046](C:\Users\HH\AppData\Roaming\Typora\typora-user-images\image-20251209154221046.png)
